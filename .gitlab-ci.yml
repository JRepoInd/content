default:
  image: docker-io.artifactory.pan.local/devdemisto/gitlab-content-ci:1.0.0.18999
  cache:
    key:
      files:
       - "dev-requirements-py3.txt"
       - "package-lock.json"
    paths:
      - venv/
      - node_modules/
    when: always
  artifacts:
    expire_in: 30 days
    paths:
      - /builds/xsoar/content/artifacts/*
    when: always
  before_script:
    - echo "=== Running before script ==="
    - git checkout $CI_COMMIT_BRANCH
    - mkdir -p -m 777 $ARTIFACTS_FOLDER/
    - |
      if [[ -f "$BASH_ENV" ]]; then
        source "$BASH_ENV"
      fi
    - source .circleci/content_release_vars.sh
    - echo "=== Creating new clean logs folder ==="
    - rm -rf $ARTIFACTS_FOLDER/logs
    - mkdir -p $ARTIFACTS_FOLDER/logs
    - echo "=== Granting execute permissions on files ==="
    - chmod +x ./Tests/scripts/*
    - chmod +x ./Tests/Marketplace/*
    - echo "=== Installing Virtualenv ==="
    - |
     if [ -f "./venv/bin/activate" ]; then
       echo "found venv"
     else
      echo "installing venv"
      NO_HOOKS=1 SETUP_PY2=yes .hooks/bootstrap > $ARTIFACTS_FOLDER/python_venv_init.log
     fi
     venv/bin/pip3 install -r .circleci/build-requirements.txt >> $ARTIFACTS_FOLDER/python_venv_init.log
     venv/bin/pip2 install -r dev-requirements-py2.txt >> $ARTIFACTS_FOLDER/python_venv_init.log
     source ./venv/bin/activate >> $ARTIFACTS_FOLDER/python_venv_init.log
    - git config diff.renameLimit 6000
    - export PATH="${PWD}/node_modules/.bin:${PATH}"
    - |
      if [ -n "${DEMISTO_SDK_NIGHTLY}" ]; then
        echo "Installing SDK"
        pip3 install git+https://github.com/demisto/demisto-sdk@master
      fi
    - echo "========= Installing SSH keys ========"
    - 'command -v ssh-agent >/dev/null || ( apt-get update -y && apt-get install openssh-client -y )'
    - eval $(ssh-agent -s)
    - chmod 400 $OREGON_CI_KEY
    - ssh-add $OREGON_CI_KEY
    - mkdir -p ~/.ssh
    - chmod 700 ~/.ssh

    - echo "======= Download configuration ========"
    - ./Tests/scripts/download_demisto_conf.sh

    - echo "========== Build Parameters =========="
    - set | grep -E "^NIGHTLY=|^INSTANCE_TESTS=|^SERVER_BRANCH_NAME=|^ARTIFACT_BUILD_NUM=|^DEMISTO_SDK_NIGHTLY=|^TIME_TO_LIVE=|^CONTRIB_BRANCH=|^FORCE_PACK_UPLOAD=|^PACKS_TO_UPLOAD=|^BUCKET_UPLOAD=|^GCS_MARKET_BUCKET=|^SLACK_CHANNEL="
    - python --version
    - python3 --version
    - node --version
    - npm --version
    - demisto-sdk --version


variables:
  CONTENT_VERSION: "21.3.2"
  SERVER_VERSION: "6.0.0"
  GIT_SHA1: "6fee942518c6b2275a6cb61c1824574171cf58f9" # guardrails-disable-line disable-secrets-detection
  DONT_CACHE_LAST_RESPONSE: "true"
  GCS_MARKET_BUCKET: "marketplace-dist-dev"
  SLACK_CHANNEL: "upload-flow-testing"
  DEMISTO_README_VALIDATION: "true"
  ARTIFACTS_FOLDER: "/builds/xsoar/content/artifacts"
  BASH_ENV: "/builds/xsoar/content/artifacts/bash_env"
  PYTHONPATH: "/builds/xsoar/content"
  FEATURE_BRANCH_NAME: "v4.5.0"
# Gitlab CI/CD uses shallow fetch with default depth of 50, these arguments are used to override it
# See here for more about that https://docs.gitlab.com/ee/ci/pipelines/settings.html#git-shallow-clone  # disable-secrets-detection
  GIT_STRATEGY: clone
  GIT_DEPTH: 0
  BUCKET_UPLOAD: "true"
# Remove this when branches will sync with github
  SKIP_PRIVATE_BUILD: "true"
  COMMIT_FLOW: "false"
  FORCE_BUCKET_UPLOAD: "false"

stages:
  - unittests-and-validations
  - create-instances
  - run-instances
  - upload-to-marketplace
  - notify-slack

notify-slack:
  stage: notify-slack
  when: always
  allow_failure: true
  script:
    - echo "=====Notify Slack====="
    - |
      if [ -n "${BUCKET_UPLOAD}" ]; then
        ./Tests/scripts/slack_notifier.sh 'bucket_upload_flow' '' "$SLACK_CHANNEL" 'gitlab'
      elif [ -n "${COMMIT_FLOW}" ]; then
        ./Tests/scripts/slack_notifier.sh 'unittests' $ARTIFACTS_FOLDER/env_results.json '' 'gitlab'
      fi

create-instances:
  stage: create-instances
  needs: []
  script:
    - demisto-sdk create-id-set -o ./Tests/id_set.json > $ARTIFACTS_FOLDER/create_instances_create_id_set_output.log
    - cp ./Tests/id_set.json $ARTIFACTS_FOLDER
    - python3 Utils/release_notes_generator.py $CONTENT_VERSION $CI_COMMIT_SHA $CI_BUILD_ID --output $ARTIFACTS_FOLDER/packs-release-notes.md --github-token $GITHUB_TOKEN
    - cp content-descriptor.json $ARTIFACTS_FOLDER
    - ./Documentation/commonServerDocs.sh
    - demisto-sdk create-content-artifacts -a $ARTIFACTS_FOLDER --cpus 8 --content_version $CONTENT_VERSION
    - gcloud auth activate-service-account --key-file="$GCS_ARTIFACTS_KEY"
    - successful_feature_branch_build=$(gsutil ls "gs://xsoar-ci-artifacts/content/$FEATURE_BRANCH_NAME/*" | tail -n 1 | grep -o -E "content/$FEATURE_BRANCH_NAME/[0-9]*")
    - echo $successful_feature_branch_build
    - python3 Utils/merge_content_new_zip.py -f $FEATURE_BRANCH_NAME -b $successful_feature_branch_build
    - zip -j $ARTIFACTS_FOLDER/uploadable_packs.zip $ARTIFACTS_FOLDER/uploadable_packs/* || ((($? > 0)) && echo "failed to zip the uploadable packs, ignoring the failure" && exit 0)
    - rm -rf $ARTIFACTS_FOLDER/uploadable_packs
    - python3 ./Tests/scripts/update_conf_json.py
    - cp "./Tests/conf.json" "$ARTIFACTS_FOLDER/conf.json"
    - |
      if [ -n "${INSTANCE_TESTS}" ];
        then
          echo "Skipping - not running in INSTANCE_TESTS build"
        else
          echo "====== Collecting tests and content packs ======"
          [ -n "${NIGHTLY}" ] && IS_NIGHTLY=true || IS_NIGHTLY=false
          python3 ./Tests/scripts/collect_tests_and_content_packs.py -n $IS_NIGHTLY
      fi
    - python3 ./Tests/Marketplace/packs_dependencies.py -i ./Tests/id_set.json -o $ARTIFACTS_FOLDER/packs_dependencies.json
    - |
      if [[ -n "${CONTRIB_BRANCH}" || -n "${DEMISTO_SDK_NIGHTLY}" ]] ; then
        echo "Skipping Preparing Content Packs For Testing since nightly instances uses production bucket"
      else
        echo "====== Preparing Content Packs For Testing ======"
        ./Tests/scripts/prepare_content_packs_for_testing.sh "$GCS_MARKET_BUCKET"
      fi
    - |
      if [[ -n "${DEMISTO_SDK_NIGHTLY}" ]] || [[ $CI_COMMIT_BRANCH != master ]] && [[ $CI_COMMIT_BRANCH != 20\.* ]] && [[ $CI_COMMIT_BRANCH != 21\.* ]]; then
        echo "Skipping packs download to artifact on non master or release branch"
      else
        ZIP_FOLDER=$(mktemp -d)
        python3 ./Tests/Marketplace/zip_packs.py -b 'marketplace-dist' -z $ZIP_FOLDER -a $ARTIFACTS_FOLDER -s $GCS_MARKET_KEY
      fi
    - |
      if [ -n "${DEMISTO_SDK_NIGHTLY}" ];
        then
          echo "Skipping - not running in INSTANCE_TESTS build"
        else
          echo "====== Uploading artifacts to GCP ======"
          ./Tests/scripts/upload_artifacts.sh
      fi
    - |
      if [ -n "${DEMISTO_SDK_NIGHTLY}" ];
        then
          echo "Skipping - not running in INSTANCE_TESTS build"
        else
          echo "====== Creating instances ======"
          [ -n "${TIME_TO_LIVE}" ] && TTL=${TIME_TO_LIVE} || TTL=300
          if [ -n "${NIGHTLY}" ] ;
            then
              export IFRA_ENV_TYPE=Nightly # disable-secrets-detection
          elif [ -n "${INSTANCE_TESTS}" ] ;
            then
              export IFRA_ENV_TYPE="Server 5.5" # disable-secrets-detection
          elif [[ -n "${CONTRIB_BRANCH}" || -n "${DEMISTO_SDK_NIGHTLY}" ]] ;
            then
              export IFRA_ENV_TYPE="Server Master" # disable-secrets-detection
          elif [ -n "${BUCKET_UPLOAD}" ] ;
            then
              export IFRA_ENV_TYPE="Bucket-Upload" # disable-secrets-detection
          else
            export IFRA_ENV_TYPE=Content-Env # disable-secrets-detection
          fi
          python3 ./Tests/scripts/awsinstancetool/aws_instance_tool.py -envType "$IFRA_ENV_TYPE" -timetolive $TTL -outfile "$ARTIFACTS_FOLDER/env_results.json"
      fi
    - echo "$CI_JOB_ID" | tee $ARTIFACTS_FOLDER/create_instances_build_num.txt  # so that later jobs in this workflow could configure the right path

.test_content_on_server_instances_base:
  needs: ["create-instances"]
  stage: run-instances
  dependencies:
    - create-instances
  rules:
    - if: '$COMMIT_FLOW == "true"'
  script:
    - export TEMP=$(cat $ARTIFACTS_FOLDER/filter_envs.json | jq ".\"$INSTANCE_ROLE\"")
# If instance was not created
    - |
      if [[ "$TEMP" != "true" && -z "${NIGHTLY}" ]];
        then
          echo "Instance with role $INSTANCE_ROLE was not created"
          exit 0
      fi
    - mv $SSH_CONFIGURATION ~/.ssh/config
    - chmod 700 ~/.ssh/config
    - Tests/scripts/open_ssh_tunnel.sh
    - python3 ./Tests/scripts/wait_until_server_ready.py "$INSTANCE_ROLE"
    - ./Tests/scripts/install_content_and_test_integrations.sh "$INSTANCE_ROLE"
    - ./Tests/scripts/run_tests.sh "$INSTANCE_ROLE"
    - |
      if [ -f ./Tests/failed_tests.txt ];
        then
          cp ./Tests/failed_tests.txt $ARTIFACTS_FOLDER/failed_tests.txt
      fi
    - |
      if [ $INSTANCE_ROLE == "Server Master" ];
        then
          ./Tests/scripts/slack_notifier.sh 'test_playbooks' $ARTIFACTS_FOLDER/env_results.json
      fi
    - python3 ./Tests/scripts/destroy_instances.py $ARTIFACTS_FOLDER $ARTIFACTS_FOLDER/env_results.json "$INSTANCE_ROLE" "$TIME_TO_LIVE"
    - export PSWD=$(jq .serverLogsZipPassword < $(cat secret_conf_path) | cut -d \" -f 2)
    - zip -P $PSWD -j $ARTIFACTS_FOLDER/Logs.zip $ARTIFACTS_FOLDER/server*.log || ((($? > 0)) && echo "Didnâ€™t find any server logs, skipping this stage" && exit 0)
    - rm -f $ARTIFACTS_FOLDER/server*.log


server_5_0:
  extends: .test_content_on_server_instances_base
  variables:
    INSTANCE_ROLE: "Server 5.0"

server_5_5:
  extends: .test_content_on_server_instances_base
  variables:
    INSTANCE_ROLE: "Server 5.5"

server_6_0:
  extends: .test_content_on_server_instances_base
  variables:
    INSTANCE_ROLE: "Server 6.0"

server_master:
  extends: .test_content_on_server_instances_base
  variables:
    INSTANCE_ROLE: "Server Master"

run-unittests-and-lint:
  needs: []
  stage: unittests-and-validations
  artifacts:
    expire_in: 48 hrs
    paths:
      - /builds/xsoar/content/unit-tests
      - /builds/xsoar/content/artifacts/*
    when: always
  script:
    - echo "====Trigger Private Build===="
    - |
      if [[ -n $FORCE_BUCKET_UPLOAD || -n $BUCKET_UPLOAD ]]; then
        if [[ $CIRCLE_BRANCH =~ pull/[0-9]+ ]] || [[ -n SKIP_PRIVATE_BUILD ]]; then
          echo "Skipping - not running in contribution instance"
        else
          python3 Utils/trigger_private_build.py --github-token $GITHUB_TOKEN
        fi
      fi
    - echo "====Test Infrustracture===="
    - python3 -m pytest ./Tests/scripts/infrastructure_tests/ -v
    - python3 -m pytest ./Tests/Marketplace/Tests/ -v
    - python3 -m pytest ./Tests/scripts/utils/tests -v
    - python3 -m pytest ./Tests/tests -v
    - python3 -m pytest ./Tests/private_build/ -v
    - python3 -m pytest Utils -v
    - |
      if [ -n "${DEMISTO_SDK_NIGHTLY}" ] ; then
      ./Tests/scripts/sdk_pylint_check.sh
      fi
    - echo "====Run Unit Testing and Lint===="
    - |
      if [[ "$(echo "$GCS_MARKET_BUCKET" | tr '[:upper:]' '[:lower:]')" != "marketplace-dist" ]]; then
        echo "Skipping validations when uploading to a test bucket."
      else
        echo "demisto-sdk version: $(demisto-sdk --version)"
        echo "mypy version: $(mypy --version)"
        echo "flake8 py2 version: $(python2 -m flake8 --version)"
        echo "flake8 py3 version: $(python3 -m flake8 --version)"
        echo "bandit py2 version: $(python2 -m bandit --version 2>&1)"
        echo "bandit py3 version: $(python3 -m bandit --version 2>&1)"
        echo "vulture py2 version: $(python2 -m vulture --version 2>&1)"
        echo "vulture py3 version: $(python3 -m vulture --version 2>&1)"
        SHOULD_LINT_ALL=$(./Tests/scripts/should_lint_all.sh)
        mkdir ./unit-tests
        if [ -n "$SHOULD_LINT_ALL" ]; then
          echo -e  "----------\nLinting all because:\n${SHOULD_LINT_ALL}\n----------"
          demisto-sdk lint -p 8 -a -q --test-xml ./unit-tests --log-path ./artifacts --failure-report ./artifacts
        else
          demisto-sdk lint -p 8 -g -v --test-xml ./unit-tests --log-path ./artifacts --failure-report ./artifacts
        fi
      fi
    - echo "====Get Private Build Status===="
    - |
      if [[ -n $FORCE_BUCKET_UPLOAD || -n $BUCKET_UPLOAD ]]; then
        if [[ $CIRCLE_BRANCH =~ pull/[0-9]+ || -n SKIP_PRIVATE_BUILD ]]; then
          echo "Skipping - not running in contribution instance"
        else
          python3 Utils/get_private_build_status.py --github-token $GITHUB_TOKEN
        fi
      fi

run-validations:
  stage: unittests-and-validations
  needs: []
  artifacts:
    expire_in: 48 hrs
    paths:
      - /builds/xsoar/content/artifacts/*
    when: always
  script:
    - echo "====Look For Secrets===="
    - demisto-sdk secrets --post-commit --ignore-entropy
    - echo "====Create id set===="
    - demisto-sdk create-id-set -o ./Tests/id_set.json > $ARTIFACTS_FOLDER/run_validations_create_id_set_output.log
    - cp ./Tests/id_set.json $ARTIFACTS_FOLDER
    - echo "====Merge public and private id sets===="
    - |
      if [[ $CI_COMMIT_BRANCH =~ pull/[0-9]+ ]]; then
          echo "Skipping, Should not run on contributor's branch."
      else
        gcloud auth activate-service-account --key-file="$GCS_MARKET_KEY" > auth.out
        echo "successfully activated google cloud service account"

        echo "Download private ID set"
        gsutil cp "gs://marketplace-dist/content/private_id_set.json" $ARTIFACTS_FOLDER/unified_id_set.json
        echo "successfully downloaded private ID set"
        gcloud auth revoke $GCS_ARTIFACTS_ACCOUNT_NAME

        echo "Merge public and private ID sets"
        demisto-sdk merge-id-sets -i1 ./Tests/id_set.json -i2 $ARTIFACTS_FOLDER/unified_id_set.json -o $CIRCLE_ARTIFACTS/unified_id_set.json
        echo "successfully merged public and private ID sets"
      fi
    - echo "====Update Tests===="
    - python3 ./Tests/scripts/update_conf_json.py
    - cp "./Tests/conf.json" "$ARTIFACTS_FOLDER/conf.json"
    - echo "====Validate Files and Yaml===="
    - |
      if [[ "$(echo "$GCS_MARKET_BUCKET" | tr '[:upper:]' '[:lower:]')" != "marketplace-dist" ]]; then
        echo "Skipping the -Validate Files and Yaml- step when uploading to a test bucket."
      else
        echo "Run flake8 on all excluding Packs (Integraions and Scripts) - they will be handled in linting"
        ./Tests/scripts/pyflake.sh *.py
        # do not run pyflake on venv or content-test-conf awsinstancetool
        find . -maxdepth 1 -type d -not \( -path . -o -path ./Packs -o -path ./venv -o -path ./Tests \) | xargs ./Tests/scripts/pyflake.sh
        ./Tests/scripts/pyflake.sh ./Tests/*.py
        find ./Tests -maxdepth 1 -type d -not \( -path ./Tests -o -path ./Tests/scripts \) | xargs ./Tests/scripts/pyflake.sh
        ./Tests/scripts/pyflake.sh ./Tests/scripts/*.py
        find ./Tests/scripts -maxdepth 1 -type d -not \( -path ./Tests/scripts -o -path ./Tests/scripts/awsinstancetool \) | xargs ./Tests/scripts/pyflake.sh
        ./Tests/scripts/validate.sh
      fi
    - echo "====Check Spelling===="
    - pip3 freeze | grep pyspellchecker
    - python3 ./Tests/scripts/circleci_spell_checker.py $CI_COMMIT_BRANCH
    - echo "====Check Build Files Are Up To Date===="
    - |
      if [[ $$CI_COMMIT_BRANCH =~ pull/[0-9]+ ]]; then
        echo "Skipping, Should not run on contributor's branch."
      else
        ./Tests/scripts/is_file_up_to_date.sh .gitlab-ci.yml
        ./Tests/scripts/is_file_up_to_date.sh .dev-requirements-py2.txt
        ./Tests/scripts/is_file_up_to_date.sh .dev-requirements-py3.txt
      fi
    - echo "====Validate content-test-conf Branch Merged===="
    - |
      if [[ $CI_COMMIT_BRANCH = "master" ]]; then
        echo "Skipping, Should not run on master branch."
      else
        # replace slashes ('/') in the branch name, if exist, with underscores ('_')
        UNDERSCORE_CI_BRANCH=${CI_COMMIT_BRANCH//\//_}
        wget --header "Accept: application/vnd.github.v3.raw" --header "Authorization: token $GITHUB_TOKEN" "https://github.com/demisto/content-test-conf/archive/$UNDERSCORE_CI_BRANCH.zip" --no-check-certificate -q || {
          if [ "$?" != "0" ]; then
            echo "No such branch in content-test-conf: $UNDERSCORE_CI_BRANCH"
          else
            echo "ERROR: Found a branch with the same name in contest-test-conf conf.json - $UNDERSCORE_CI_BRANCH.\n Merge it in order to merge the current branch into content repo."
            exit 1
          fi
        }
      fi
    - echo "====Validate landingPageSections.json===="
    - echo "Download index.zip"
    - INDEX_PATH=$(mktemp)
    - |
      gsutil cp "gs://marketplace-dist/content/packs/index.zip" $INDEX_PATH
    - echo "successfully downloaded index.zip into $INDEX_PATH"

    - UNZIP_PATH=$(mktemp -d)
    - unzip $INDEX_PATH -d $UNZIP_PATH > $ARTIFACTS_FOLDER/unzip_index.log

    - python3 Tests/Marketplace/validate_landing_page_sections.py -i $UNZIP_PATH


.start_tunnel: &start_tunnel
  - echo "=====Start Tunnel====="
  - echo "Open an ssh tunnel to the demisto servers and wait until the tunnels are established"
  - echo "Add ssh configurations"
  - |
    if [ -z $INSTANCE_CREATED ]; then
      echo "Skipping - instance was not created"
    else
      # Modifying ssh config file
      echo "Host 10.0.*
        StrictHostKeyChecking no
        LogLevel ERROR
        ProxyJump content-build@content-build-lb.demisto.works  # disable-secrets-detection
       Host content-build-lb.demisto.works
        Port 43567
        UserKnownHostsFile /dev/null
        StrictHostKeyChecking no
        LogLevel ERROR" >> ~/.ssh/config
    fi
  - echo "Open SSH Tunnel"
  - |
    if [ -z $INSTANCE_CREATED ]; then
      echo "Skipping - instance was not created"
    else
      echo "Generating the ips and ports"
      # Generating the ips and ports with the following form: <instance-ip> <tunnel-port>
      IPS_AND_PORTS=$(cat $ARTIFACTS_FOLDER/env_results.json | jq ".[] | select(.Role==\"$INSTANCE_ROLE\")" | jq -r '[.InstanceDNS, .TunnelPort] | @tsv' | sed "s/\"//g")
      # Handling the ip & port pairs line by line
      echo "Handling the ip & port pairs line by line"
      echo $IPS_AND_PORTS | grep -o -E "[0-9\.]+ [0-9]{4}" | while read IP_AND_PORT;
      do
        # Capturing the IP
        echo "Capturing the IP"
        IP=$(echo $IP_AND_PORT | grep -o -E "10\.0\.[0-9]{1,3}\.[0-9]{1,3}")
        # Capturing the port
        echo "Capturing the port"
        PORT=$(echo $IP_AND_PORT | grep -o -E "[0-9]{4}")
        echo "Opening a tunnel for ip $IP with port $PORT"
        ssh -4 -o "ServerAliveInterval=15" -f -N "content-build@content-build-lb.demisto.works" -L "$PORT:$IP:443"  # disable-secrets-detection
        echo "Waiting for tunnel to be established"
        until nc -z 127.0.0.1 $PORT -v;
        do
          if [ $COUNT -ge $SSH_TUNNEL_TIMEOUT ]; then
            echo "ssh tunnel set up timeout on instance with ip $IP";
            exit 1;
          fi;
          ((COUNT++))
          sleep 1
        done
      done
    fi

.check_user_permissions_to_upload_packs: &check_user_permissions_to_upload_packs
  - echo "=====Check User Permissions to Upload Packs=====" # if bucket upload and uploading to marketplace-dist
  - |
    if [[ -n "${BUCKET_UPLOAD}" || -n "${FORCE_BUCKET_UPLOAD}" ]] && [[ "$GCS_MARKET_BUCKET" == "marketplace-dist" ]]; then
      CONTENT_LEADERS=$(curl -sS "https://api.github.com/orgs/demisto/teams/content-leaders/members" -H "Authorization: token ${GITHUB_TOKEN}")
      echo "recieved content leaders"
      LEADER_NAMES=$(echo $CONTENT_LEADERS | jq -r ".[].login")
      LEADER_NAMES=$(echo "${LEADER_NAMES}" "content-bot" )
      if [[ -z "$GITLAB_USER_NAME" ]] || [[ -z "`echo $LEADER_NAMES | grep -w "$GITLAB_USER_NAME"`" ]]; then
        echo -e "User '$GITLAB_USER_NAME' is not allowed to trigger this build, only one of:\n${LEADER_NAMES}"
        exit 1
      else
        echo "User '${GITLAB_USER_NAME}' is allowed to upload packs / force upload packs."
      fi
    fi

.install_packs_in_server:
  needs: ["create-instances"]
  stage: run-instances
  artifacts:
    expire_in: 48 hrs
    paths:
      - /builds/xsoar/content/artifacts/*
    when: always
  variables:
    INSTANCE_CREATED: "true"
    SSH_TUNNEL_TIMEOUT: 10
    TIME_TO_LIVE: ""
  rules:
    - if: '$BUCKET_UPLOAD == "true"'
  script:
    - *start_tunnel
    - echo "=====Get Instance Variables====="
    - echo INSTANCE_ROLE="$INSTANCE_ROLE"
    - echo INSTANCE_CREATED="$INSTANCE_CREATED"
    - echo "=====Wait Until Server Ready====="
    - python3 ./Tests/scripts/wait_until_server_ready.py "$INSTANCE_ROLE" "$ARTIFACTS_FOLDER" "gitlab"
    - echo "=====Install Packs====="
    - ./Tests/Marketplace/install_packs.sh "$INSTANCE_ROLE" "gitlab"
    - echo "=====Notify Slack====="
    - |
      if [ -n "${BUCKET_UPLOAD}" ]; then
        ./Tests/scripts/slack_notifier.sh 'bucket_upload_flow' '' "$SLACK_CHANNEL" 'gitlab'
      fi
    - echo "=====Destroy Instances====="
    - |
      if [ -n "${CONTRIB_BRANCH}" ]; then
        echo "Skipping - not running in contribution instance"
      else
        python3 ./Tests/scripts/destroy_instances.py $ARTIFACTS_FOLDER $ARTIFACTS_FOLDER/env_results.json "$INSTANCE_ROLE" "$TIME_TO_LIVE"

        export PSWD=$(jq .serverLogsZipPassword < $(cat secret_conf_path) | cut -d \" -f 2)
        zip -P $PSWD -j $ARTIFACTS_FOLDER/Logs.zip $ARTIFACTS_FOLDER/server*.log || ((($? > 0)) && echo "Didnâ€™t find any server logs, skipping this stage" && exit 0)
        rm -f $ARTIFACTS_FOLDER/server*.log
      fi

install-packs-in-server6_0:
  extends: .install_packs_in_server
  variables:
    INSTANCE_ROLE: "Server 6.0"

install-packs-in-server-master:
  extends: .install_packs_in_server
  variables:
    INSTANCE_ROLE: "Server Master"

upload-packs-to-marketplace:
  needs: ["run-validations", "run-unittests-and-lint", "install-packs-in-server6_0", "install-packs-in-server-master"]
  stage: upload-to-marketplace
  artifacts:
    expire_in: 48 hrs
    paths:
      - /builds/xsoar/content/artifacts/*
    when: always
  variables:
    INSTANCE_ROLE: "Server Master"
    INSTANCE_CREATED: "true"
    SSH_TUNNEL_TIMEOUT: 10
    TIME_TO_LIVE: ""
  rules:
    - if: '$BUCKET_UPLOAD == "true"'
  script:
    - *start_tunnel
    - *check_user_permissions_to_upload_packs
    - echo "=====Upload Packs To Marketplace Storage====="
    - |
      if [[ "$CI_COMMIT_BRANCH" == "master" ]] || [[ "$GCS_MARKET_BUCKET" != "marketplace-dist" ]]; then
        EXTRACT_FOLDER=$(mktemp -d)
        PACK_ARTIFACTS=$ARTIFACTS_FOLDER/content_packs.zip
        PACKS_DEPENDENCIES=$ARTIFACTS_FOLDER/packs_dependencies.json
        GCS_PATH=$(mktemp)
        CI_COMMIT_BRANCH=${CI_COMMIT_BRANCH:-unknown}
        CREATE_INSTANCES_JOB_NUMBER=$(cat $ARTIFACTS_FOLDER/create_instances_build_num.txt)
        echo $GCS_MARKET_KEY > $GCS_PATH

        GCS_BUILD_BUCKET="marketplace-ci-build"
        if [[ $GCS_MARKET_BUCKET != "marketplace-dist" ]]; then
          STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CREATE_INSTANCES_JOB_NUMBER/content/packs"
        fi

        python3 ./Tests/Marketplace/copy_and_upload_packs.py -a $PACK_ARTIFACTS -e $EXTRACT_FOLDER -pb "$GCS_MARKET_BUCKET" -bb "$GCS_BUILD_BUCKET" -s $GCS_PATH -n $CREATE_INSTANCES_JOB_NUMBER -c $CI_COMMIT_BRANCH -pbp "$STORAGE_BASE_PATH"
        rm $GCS_PATH
      fi
    - echo "=====Validate Premium Packs====="
    - |
      if [[ "$CI_COMMIT_BRANCH" == "master" ]] || [[ "$GCS_MARKET_BUCKET" != "marketplace-dist" ]]; then
        ./Tests/scripts/validate_premium_packs.sh "$INSTANCE_ROLE"
      else
        echo "Skipping Premium Packs Validation"
      fi

force-pack-upload:
  stage: upload-to-marketplace
  needs: ["create-instances"]
  rules:
    - if: '$FORCE_BUCKET_UPLOAD == "true"'
  script:
    - *check_user_permissions_to_upload_packs
    - EXTRACT_FOLDER=$(mktemp -d)
    - PACK_ARTIFACTS=$CIRCLE_ARTIFACTS/content_packs.zip
    - PACKS_DEPENDENCIES=$CIRCLE_ARTIFACTS/packs_dependencies.json
    - CIRCLE_BRANCH=${CIRCLE_BRANCH:-unknown}
    - GCS_BUILD_BUCKET="marketplace-ci-build"
    - |
      if [[ $GCS_MARKET_BUCKET != "marketplace-dist" ]]; then
          STORAGE_BASE_PATH="upload-flow/builds/$CIRCLE_BRANCH/$CI_PIPELINE_ID/content/packs"
      fi
    - python3 ./Tests/Marketplace/copy_and_upload_packs.py -a $PACK_ARTIFACTS -e $EXTRACT_FOLDER -pb "$GCS_MARKET_BUCKET" -bb "$GCS_BUILD_BUCKET" -s $GCS_MARKET_KEY -n $CI_PIPELINE_ID -c $CI_COMMIT_BRANCH -p "${PACKS_TO_UPLOAD}" -pbp "${STORAGE_BASE_PATH}"